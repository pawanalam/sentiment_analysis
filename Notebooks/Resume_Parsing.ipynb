{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db3523e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Obtaining dependency information for PyMuPDF from https://files.pythonhosted.org/packages/71/c2/a9059607f80dcaf2392f991748cfc53456820392c0220cff02572653512a/pymupdf-1.25.5-cp39-abi3-win_amd64.whl.metadata\n",
      "  Downloading pymupdf-1.25.5-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pymupdf-1.25.5-cp39-abi3-win_amd64.whl (16.6 MB)\n",
      "   ---------------------------------------- 0.0/16.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/16.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/16.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/16.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/16.6 MB 245.8 kB/s eta 0:01:08\n",
      "   ---------------------------------------- 0.1/16.6 MB 595.3 kB/s eta 0:00:28\n",
      "    --------------------------------------- 0.2/16.6 MB 935.2 kB/s eta 0:00:18\n",
      "    --------------------------------------- 0.3/16.6 MB 1.3 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.5/16.6 MB 1.6 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.7/16.6 MB 1.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.9/16.6 MB 2.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.1/16.6 MB 2.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.3/16.6 MB 2.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.5/16.6 MB 2.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.6/16.6 MB 2.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.8/16.6 MB 2.8 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.0/16.6 MB 3.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.2/16.6 MB 3.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.4/16.6 MB 3.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.6/16.6 MB 3.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.9/16.6 MB 3.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 3.1/16.6 MB 3.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.4/16.6 MB 3.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.6/16.6 MB 3.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.9/16.6 MB 3.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 4.2/16.6 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 4.5/16.6 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 4.9/16.6 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 5.2/16.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.5/16.6 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.9/16.6 MB 4.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 6.3/16.6 MB 4.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 6.6/16.6 MB 4.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 7.0/16.6 MB 4.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 7.4/16.6 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.7/16.6 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 8.1/16.6 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.4/16.6 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.7/16.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 9.1/16.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.6/16.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 10.0/16.6 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 10.3/16.6 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.6/16.6 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 11.0/16.6 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 11.2/16.6 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 11.6/16.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 12.0/16.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 12.3/16.6 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.6/16.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 13.0/16.6 MB 7.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 13.4/16.6 MB 7.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.8/16.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 14.1/16.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 14.4/16.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.7/16.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 15.1/16.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.5/16.6 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.7/16.6 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 16.0/16.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.3/16.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.6/16.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.6/16.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.6/16.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.6/16.6 MB 6.6 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.25.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f8b41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Page 1 ---\n",
      "\n",
      "NIKHIL .M. SUTAR\n",
      "SUMMARY\n",
      "Innovative developer with expertise in C, Java, Python, and JavaScript. Proficient in utilizing frameworks such\n",
      "as Flask, Django, and Bootstrap, with ongoing learning in React.js. Experienced in version control with Git and\n",
      "GitHub and adept at deploying projects on Vercel. Committed to leveraging AI tools, including ChatGPT, to\n",
      "enhance project outcomes. Seeking a dynamic role to apply technical skills and drive project success.\n",
      "PROJECTS\n",
      "EDUCATION\n",
      "Live Link : https://success-classes-of-engineering.vercel.app/\n",
      "Frontend : HTML , CSS \n",
      "Backend : Flask , Python\n",
      "2. Success Classes of Engineering\n",
      "    Jun 2024  - Jun 2024\n",
      "ADDITIONAL INFORMATION\n",
      "Another Skills Certification :  PC Operation (Excel, PowerPoint, Word), Power BI\n",
      "Languages: English, Hindi , Marathi\n",
      "Hobbies: Drawing Architectural structures \n",
      "4. Portfolio Website\n",
      "Live Link : https://carpentrycoder.github.io/Resume/\n",
      "Frontend: HTML , JS , Tailwind CSS\n",
      "Jan 2025 - Jan 2025\n",
      "Github | +91-7738544966 | nikhilsutar621@gmail.com | LinkedIn\n",
      "SKILLS \n",
      "Languages : C , Java , Python , Javascript, Sql\n",
      "Frontend :  Bootstrap , React.js \n",
      "Backend : Node.js , Flask , Django\n",
      "Python Libraries :  Pandas , Numpy , Matplotlib, Seaborn\n",
      "Artificial Intelligence : Scikit-Learn, Machine Learning, LLMs , Hugging Face , Transformers\n",
      "3. Pranav Interiors And Desingers\n",
      "Live Link : https://pranav-interiors-and-decorators.onrender.com/\n",
      "Frontend: HTML, CSS\n",
      "Backend: Django, Python\n",
      "Database: PostgreSQL\n",
      "Hosting: Render\n",
      "Jan 2025 - Jan 2025\n",
      "Current Update : LinkedIN Post \n",
      "Frontend : HTML , CSS \n",
      "Backend : D-Jango, LLM \n",
      "1. SaleGyaan : AI-Based E-commerce Sales Prediction\n",
      "    Dec 2024 - Present\n",
      "Konkan Gyanpeeth College of Engineering , affiliated to the University of Mumbai    \n",
      "Artificial Intelligence and Data Science | CGPA of 5 sems: 6.70       \n",
      " 2023 -  2026 (expected)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Module 1: Read and Print Resume PDF\n",
    "import fitz  # PyMuPDF\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the path to your resume PDF\n",
    "pdf_path = \"TE_Resume.pdf\"  # <- Change this to your actual PDF path\n",
    "\n",
    "# Open the PDF\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "# Extract and print text from all pages\n",
    "for page_num, page in enumerate(doc, start=1):\n",
    "    resume_text = page.get_text()\n",
    "    text = resume_text\n",
    "    print(f\"\\n--- Page {page_num} ---\\n\")\n",
    "    print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77502982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4     GitHub and adept at deploying projects on Verc...\n",
      "23             https://carpentrycoder.github.io/Resume/\n",
      "26                                         Github | +91\n",
      "28     7738544966 | nikhilsutar621@gmail.com | LinkedIn\n",
      "44                                        LinkedIN Post\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "contact_info = resume_df[\"text\"].str.contains(r\"\\+91|\\@|gmail\\.com|LinkedIn|GitHub\", case=False)\n",
    "print(resume_df[contact_info][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2695d826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Final Structured Resume Data:\n",
      "\n",
      "{'additional_info': {'Another Skills Certification': ['PC Operation (Excel', 'PowerPoint', 'Word)', 'Power BI'],\n",
      "                     'Frontend': ['HTML', 'JS', 'Tailwind CSS'],\n",
      "                     'Hobbies': ['Drawing Architectural structures'],\n",
      "                     'Languages': ['English', 'Hindi', 'Marathi'],\n",
      "                     'Live Link': ['https://carpentrycoder.github.io/Resume/']},\n",
      " 'contact': {'email': 'nikhilsutar621@gmail.com', 'github': 'Github', 'linkedin': 'LinkedIn', 'phone': '+91-7738544966'},\n",
      " 'education': 'Live Link : https://success-classes-of-engineering.vercel.app/\\n'\n",
      "              'Frontend : HTML , CSS \\n'\n",
      "              'Backend : Flask , Python\\n'\n",
      "              '2. Success Classes of Engineering\\n'\n",
      "              '    Jun 2024  - Jun 2024\\n'\n",
      "              'ADDITIONAL INFORMATION\\n'\n",
      "              'Another Skills Certification :  PC Operation (Excel, PowerPoint, Word), Power BI\\n'\n",
      "              'Languages: English, Hindi , Marathi\\n'\n",
      "              'Hobbies: Drawing Architectural structures \\n'\n",
      "              '4. Portfolio Website\\n'\n",
      "              'Live Link : https://carpentrycoder.github.io/Resume/\\n'\n",
      "              'Frontend: HTML , JS , Tailwind CSS\\n'\n",
      "              'Jan 2025 - Jan 2025\\n'\n",
      "              'Github | +91-7738544966 | nikhilsutar621@gmail.com | LinkedIn',\n",
      " 'name': 'NIKHIL .M. SUTAR',\n",
      " 'projects': [],\n",
      " 'skills': {},\n",
      " 'summary': 'Innovative developer with expertise in C, Java, Python, and JavaScript. Proficient in utilizing frameworks such\\n'\n",
      "            'as Flask, Django, and Bootstrap, with ongoing learning in React.js. Experienced in version control with Git and\\n'\n",
      "            'GitHub and adept at deploying projects on Vercel. Committed to leveraging AI tools, including ChatGPT, to\\n'\n",
      "            'enhance project outcomes. Seeking a dynamic role to apply technical skills and drive project success.'}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "\n",
    "# Read PDF\n",
    "pdf_path = \"TE_Resume.pdf\"\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "# Extract full text\n",
    "resume_text = \"\\n\".join(page.get_text() for page in doc)\n",
    "\n",
    "# ---------- STRUCTURED PARSING ----------\n",
    "structured_resume = {}\n",
    "\n",
    "# Name (assume first non-empty line)\n",
    "lines = resume_text.splitlines()\n",
    "structured_resume[\"name\"] = next((line.strip() for line in lines if line.strip()), \"Unknown Name\")\n",
    "\n",
    "# Summary\n",
    "summary_match = re.search(r\"SUMMARY\\n(.*?)\\nPROJECTS\", resume_text, re.DOTALL)\n",
    "structured_resume[\"summary\"] = summary_match.group(1).strip() if summary_match else \"\"\n",
    "\n",
    "# Projects\n",
    "projects_section = re.search(r\"PROJECTS\\n(.*?)\\nEDUCATION\", resume_text, re.DOTALL)\n",
    "projects = []\n",
    "if projects_section:\n",
    "    raw = projects_section.group(1).strip()\n",
    "    project_entries = re.split(r\"\\n\\d+\\.\\s\", raw)\n",
    "    for entry in project_entries[1:]:\n",
    "        lines = entry.strip().splitlines()\n",
    "        title = lines[0] if lines else \"Untitled\"\n",
    "        details = \"\\n\".join(lines[1:]) if len(lines) > 1 else \"\"\n",
    "        projects.append({\"title\": title, \"details\": details})\n",
    "structured_resume[\"projects\"] = projects\n",
    "\n",
    "# Education\n",
    "edu_match = re.search(r\"EDUCATION\\n(.*?)\\nSKILLS\", resume_text, re.DOTALL)\n",
    "structured_resume[\"education\"] = edu_match.group(1).strip() if edu_match else \"\"\n",
    "\n",
    "# Skills\n",
    "skills_match = re.search(r\"SKILLS\\s+(.*?)\\nADDITIONAL INFORMATION\", resume_text, re.DOTALL)\n",
    "skills_text = skills_match.group(1).strip() if skills_match else \"\"\n",
    "skills = {}\n",
    "for line in skills_text.splitlines():\n",
    "    if \":\" in line:\n",
    "        key, value = line.split(\":\", 1)\n",
    "        skills[key.strip()] = [v.strip() for v in value.split(\",\")]\n",
    "structured_resume[\"skills\"] = skills\n",
    "\n",
    "# Additional Info\n",
    "add_info_match = re.search(r\"ADDITIONAL INFORMATION\\n(.*?)(Github|\\+91|Email|LinkedIn)\", resume_text, re.DOTALL)\n",
    "additional_text = add_info_match.group(1).strip() if add_info_match else \"\"\n",
    "additional = {}\n",
    "for line in additional_text.splitlines():\n",
    "    if \":\" in line:\n",
    "        key, value = line.split(\":\", 1)\n",
    "        additional[key.strip()] = [v.strip() for v in value.split(\",\")]\n",
    "structured_resume[\"additional_info\"] = additional\n",
    "\n",
    "# Contact info: grab line with all 4 parts\n",
    "contact_line = next((line for line in lines if \"Github\" in line and \"|\" in line), \"\")\n",
    "contact_parts = [part.strip() for part in contact_line.split(\"|\")]\n",
    "contact_keys = [\"github\", \"phone\", \"email\", \"linkedin\"]\n",
    "structured_resume[\"contact\"] = {k: contact_parts[i] if i < len(contact_parts) else \"N/A\"\n",
    "                                 for i, k in enumerate(contact_keys)}\n",
    "\n",
    "# ---------- Print Final Output ----------\n",
    "print(\"\\nâœ… Final Structured Resume Data:\\n\")\n",
    "pprint.pprint(structured_resume, width=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d36b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Page 1 ---\n",
      "NIKHIL .M. SUTAR\n",
      "SUMMARY\n",
      "Innovative developer with expertise in C, Java, Python, and JavaScript. Proficient in utilizing frameworks such\n",
      "as Flask, Django, and Bootstrap, with ongoing learning in React.js. Experienced in version control with Git and\n",
      "GitHub and adept at deploying projects on Vercel. Committed to leveraging AI tools, including ChatGPT, to\n",
      "enhance project outcomes. Seeking a dynamic role to apply technical skills and drive project success.\n",
      "PROJECTS\n",
      "EDUCATION\n",
      "Live Link : https://success-classes-of-engineering.vercel.app/\n",
      "Frontend : HTML , CSS \n",
      "Backend : Flask , Python\n",
      "2. Success Classes of Engineering\n",
      "    Jun 2024  - Jun 2024\n",
      "ADDITIONAL INFORMATION\n",
      "Another Skills Certification :  PC Operation (Excel, PowerPoint, Word), Power BI\n",
      "Languages: English, Hindi , Marathi\n",
      "Hobbies: Drawing Architectural structures \n",
      "4. Portfolio Website\n",
      "Live Link : https://carpentrycoder.github.io/Resume/\n",
      "Frontend: HTML , JS , Tailwind CSS\n",
      "Jan 2025 - Jan 2025\n",
      "Github | +91-7738544966 | nikhilsutar621@gmail.com | LinkedIn\n",
      "SKILLS \n",
      "Languages : C , Java , Python , Javascript, Sql\n",
      "Frontend :  Bootstrap , React.js \n",
      "Backend : Node.js , Flask , Django\n",
      "Python Libraries :  Pandas , Numpy , Matplotlib, Seaborn\n",
      "Artificial Intelligence : Scikit-Learn, Machine Learning, LLMs , Hugging Face , Transformers\n",
      "3. Pranav Interiors And Desingers\n",
      "Live Link : https://pranav-interiors-and-decorators.onrender.com/\n",
      "Frontend: HTML, CSS\n",
      "Backend: Django, Python\n",
      "Database: PostgreSQL\n",
      "Hosting: Render\n",
      "Jan 2025 - Jan 2025\n",
      "Current Update : LinkedIN Post \n",
      "Frontend : HTML , CSS \n",
      "Backend : D-Jango, LLM \n",
      "1. SaleGyaan : AI-Based E-commerce Sales Prediction\n",
      "    Dec 2024 - Present\n",
      "Konkan Gyanpeeth College of Engineering , affiliated to the University of Mumbai    \n",
      "Artificial Intelligence and Data Science | CGPA of 5 sems: 6.70       \n",
      " 2023 -  2026 (expected)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += f\"\\n--- Page {page.number + 1} ---\\n\"\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# ðŸ“‚ Replace this with your resume file path\n",
    "pdf_path = \"TE_Resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "print(resume_text[:5000])  # printing only first 1000 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bced8709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Page 1 ---\n",
      "NIKHIL .M. SUTAR\n",
      "SUMMARY\n",
      "Innovative developer with expertise in C, Java, Python, and JavaScript. Proficient in utilizing frameworks such\n",
      "as Flask, Django, and Bootstrap, with ongoing learning in React.js. Experienced in version control with Git and\n",
      "GitHub and adept at deploying projects on Vercel. Committed to leveraging AI tools, including ChatGPT, to\n",
      "enhance project outcomes. Seeking a dynamic role to apply technical skills and drive project success.\n",
      "PROJECTS\n",
      "EDUCATION\n",
      "Live Link : https://success-classes-of-engineering.vercel.app/\n",
      "Frontend : HTML , CSS Backend : Flask , Python\n",
      "2. Success Classes of Engineering Jun 2024 - Jun 2024\n",
      "ADDITIONAL INFORMATION\n",
      "Another Skills Certification : PC Operation (Excel, PowerPoint, Word), Power BI\n",
      "Languages: English, Hindi , Marathi\n",
      "Hobbies: Drawing Architectural structures 4. Portfolio Website\n",
      "Live Link : https://carpentrycoder.github.io/Resume/\n",
      "Frontend: HTML , JS , Tailwind CSS\n",
      "Jan 2025 - Jan 2025\n",
      "Github | +91-7738544966 | nikhilsutar621@gmail.com | LinkedIn\n",
      "SKILLS Languages : C , Java , Python , Javascript, Sql\n",
      "Frontend : Bootstrap , React.js Backend : Node.js , Flask , Django\n",
      "Python Libraries : Pandas , Numpy , Matplotlib, Seaborn\n",
      "Artificial Intelligence : Scikit-Learn, Machine Learning, LLMs , Hugging Face , Transformers\n",
      "3. Pranav Interiors And Desingers\n",
      "Live Link : https://pranav-interiors-and-decorators.onrender.com/\n",
      "Frontend: HTML, CSS\n",
      "Backend: Django, Python\n",
      "Database: PostgreSQL\n",
      "Hosting: Render\n",
      "Jan 2025 - Jan 2025\n",
      "Current Update : LinkedIN Post Frontend : HTML , CSS Backend : D-Jango, LLM 1. SaleGyaan : AI-Based E-commerce Sales Prediction Dec 2024 - Present\n",
      "Konkan Gyanpeeth College of Engineering , affiliated to the University of Mumbai Artificial Intelligence and Data Science | CGPA of 5 sems: 6.70 2023 - 2026 (expected)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\n+', '\\n', text)  # remove extra line breaks\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)  # remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "cleaned_resume = clean_text(resume_text)\n",
    "print(cleaned_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b4223f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: NIKHIL .M. SUTAR\n",
      "Email: nikhilsutar621@gmail.com\n",
      "Phone: +91-7738544966\n",
      "Skills (27 matched): C, Machine Learning, Bootstrap, Excel, SQL, Tailwind CSS, Scikit-Learn, Git, HTML, Pandas, Django, Python, NumPy, Flask, Hugging Face, React.js, Seaborn, Node.js, Matplotlib, JavaScript, PostgreSQL, GitHub, Java, Transformers, LLMs, CSS, Power BI\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# âœ… Expanded Skills Database (you can keep updating this!)\n",
    "SKILLS_DB = [\n",
    "    'C', 'C++', 'Java', 'Python', 'JavaScript', 'TypeScript', 'HTML', 'CSS', 'SQL',\n",
    "    'Bootstrap', 'Tailwind CSS', 'React.js', 'Vue.js', 'Angular',\n",
    "    'Flask', 'Django', 'Node.js', 'Express.js',\n",
    "    'Pandas', 'NumPy', 'Matplotlib', 'Seaborn', 'Plotly',\n",
    "    'Scikit-Learn', 'Machine Learning', 'Deep Learning', 'LLMs',\n",
    "    'Hugging Face', 'Transformers', 'TensorFlow', 'PyTorch',\n",
    "    'OpenCV', 'Power BI', 'Excel', 'Git', 'GitHub', 'Docker', 'PostgreSQL', 'MongoDB'\n",
    "]\n",
    "\n",
    "def extract_email(text):\n",
    "    match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "def extract_phone(text):\n",
    "    match = re.search(r'\\+91[-\\s]?[0-9]{10}|\\b[7-9]\\d{9}\\b', text)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "def extract_name(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if \"SUMMARY\" in line.upper():\n",
    "            return lines[lines.index(line) - 1].strip()\n",
    "    return \"Name not found\"\n",
    "\n",
    "def extract_skills(text):\n",
    "    text = text.lower()\n",
    "    found_skills = []\n",
    "    for skill in SKILLS_DB:\n",
    "        if skill.lower() in text:\n",
    "            found_skills.append(skill)\n",
    "    return list(set(found_skills))  # Unique skills only\n",
    "\n",
    "# --- Assuming 'cleaned_resume' and 'resume_text' are defined already ---\n",
    "email = extract_email(cleaned_resume)\n",
    "phone = extract_phone(cleaned_resume)\n",
    "name = extract_name(resume_text)\n",
    "skills = extract_skills(cleaned_resume)\n",
    "\n",
    "# ðŸ–¨ï¸ Output Results\n",
    "print(\"Name:\", name)\n",
    "print(\"Email:\", email)\n",
    "print(\"Phone:\", phone)\n",
    "print(f\"Skills ({len(skills)} matched):\", ', '.join(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55363943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: NIKHIL .M. SUTAR\n",
      "Email: nikhilsutar621@gmail.com\n",
      "Phone: +91-7738544966\n",
      "Skills (27 matched): C, Machine Learning, Bootstrap, Excel, SQL, Scikit-Learn, Tailwind CSS, Git, HTML, Pandas, Django, Python, NumPy, Flask, Hugging Face, React.js, Seaborn, Node.js, Matplotlib, JavaScript, PostgreSQL, GitHub, Java, Transformers, LLMs, CSS, Power BI\n",
      "\n",
      "Education Section:\n",
      "- konkan gyanpeeth college of engineering , affiliated to the university of mumbai artificial intelligence and data science | cgpa of 5 sems: 6.70 2023 - 2026 (expected)\n",
      "\n",
      "Experience / Projects Section:\n",
      "- summary\n",
      "- innovative developer with expertise in c, java, python, and javascript. proficient in utilizing frameworks such\n",
      "- as flask, django, and bootstrap, with ongoing learning in react.js. experienced in version control with git and\n",
      "- github and adept at deploying projects on vercel. committed to leveraging ai tools, including chatgpt, to\n",
      "- enhance project outcomes. seeking a dynamic role to apply technical skills and drive project success.\n",
      "- projects\n",
      "- 2. success classes of engineering jun 2024 - jun 2024\n",
      "- languages: english, hindi , marathi\n",
      "- jan 2025 - jan 2025\n",
      "- frontend : bootstrap , react.js backend : node.js , flask , django\n",
      "- live link : https://pranav-interiors-and-decorators.onrender.com/\n",
      "- backend: django, python\n",
      "- jan 2025 - jan 2025\n",
      "- current update : linkedin post frontend : html , css backend : d-jango, llm 1. salegyaan : ai-based e-commerce sales prediction dec 2024 - present\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample predefined skill set\n",
    "SKILLS_DB = [\n",
    "    'C', 'C++', 'Java', 'Python', 'JavaScript', 'HTML', 'CSS', 'SQL',\n",
    "    'Bootstrap', 'React.js', 'Flask', 'Django', 'Node.js',\n",
    "    'Pandas', 'NumPy', 'Matplotlib', 'Seaborn',\n",
    "    'Scikit-Learn', 'Machine Learning', 'LLMs',\n",
    "    'Hugging Face', 'Transformers', 'Power BI',\n",
    "    'Excel', 'Git', 'GitHub', 'PostgreSQL', 'Tailwind CSS'\n",
    "]\n",
    "\n",
    "def extract_email(text):\n",
    "    match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "def extract_phone(text):\n",
    "    match = re.search(r'\\+91[-\\s]?[0-9]{10}|\\b[7-9]\\d{9}\\b', text)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "def extract_name(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if \"SUMMARY\" in line.upper():\n",
    "            return lines[lines.index(line) - 1].strip()\n",
    "    return \"Name not found\"\n",
    "\n",
    "def extract_skills(text):\n",
    "    text = text.lower()\n",
    "    found_skills = [skill for skill in SKILLS_DB if skill.lower() in text]\n",
    "    return list(set(found_skills))\n",
    "\n",
    "def extract_education(text):\n",
    "    education_keywords = ['university', 'college', 'bachelor', 'master', 'b.tech', 'm.tech', 'cgpa', 'degree']\n",
    "    lines = text.lower().split(\"\\n\")\n",
    "    education = [line.strip() for line in lines if any(keyword in line for keyword in education_keywords)]\n",
    "    return education if education else [\"Education info not found\"]\n",
    "\n",
    "def extract_experience(text):\n",
    "    experience_keywords = ['project', 'experience', 'internship', 'jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "    lines = text.lower().split(\"\\n\")\n",
    "    experience = [line.strip() for line in lines if any(keyword in line for keyword in experience_keywords)]\n",
    "    return experience if experience else [\"Experience info not found\"]\n",
    "\n",
    "# Run the extractors\n",
    "email = extract_email(cleaned_resume)\n",
    "phone = extract_phone(cleaned_resume)\n",
    "name = extract_name(resume_text)\n",
    "skills = extract_skills(cleaned_resume)\n",
    "education = extract_education(cleaned_resume)\n",
    "experience = extract_experience(cleaned_resume)\n",
    "\n",
    "# Print the results\n",
    "print(\"Name:\", name)\n",
    "print(\"Email:\", email)\n",
    "print(\"Phone:\", phone)\n",
    "print(f\"Skills ({len(skills)} matched):\", ', '.join(skills))\n",
    "print(\"\\nEducation Section:\")\n",
    "for edu in education:\n",
    "    print(\"-\", edu)\n",
    "\n",
    "print(\"\\nExperience / Projects Section:\")\n",
    "for exp in experience:\n",
    "    print(\"-\", exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c70e636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“› Name: NIKHIL .M. SUTAR\n",
      "ðŸ“§ Email: nikhilsutar621@gmail.com\n",
      "ðŸ“ž Phone: +91-7738544966\n",
      "ðŸ§  Skills Matched: 27\n",
      "ðŸ§© Skills: ['C', 'Machine Learning', 'Bootstrap', 'Excel', 'SQL', 'Tailwind CSS', 'Scikit-Learn', 'Git', 'HTML', 'Pandas', 'Django', 'Python', 'NumPy', 'Flask', 'Hugging Face', 'React.js', 'Seaborn', 'Node.js', 'Matplotlib', 'JavaScript', 'PostgreSQL', 'GitHub', 'Java', 'Transformers', 'LLMs', 'CSS', 'Power BI']\n",
      "\n",
      "ðŸŽ“ Education:\n",
      "- konkan gyanpeeth college of engineering , affiliated to the university of mumbai\n",
      "- artificial intelligence and data science | cgpa of 5 sems: 6.70\n",
      "\n",
      "ðŸ’¼ Experience & Project Highlights:\n",
      "- summary\n",
      "- as flask, django, and bootstrap, with ongoing learning in react.js. experienced in version control with git and\n",
      "- github and adept at deploying projects on vercel. committed to leveraging ai tools, including chatgpt, to\n",
      "- projects\n",
      "- live link : https://success-classes-of-engineering.vercel.app/\n",
      "- jun 2024  - jun 2024\n",
      "- live link : https://carpentrycoder.github.io/resume/\n",
      "- jan 2025 - jan 2025\n",
      "- github | +91-7738544966 | nikhilsutar621@gmail.com | linkedin\n",
      "- backend : node.js , flask , django\n",
      "- live link : https://pranav-interiors-and-decorators.onrender.com/\n",
      "- backend: django, python\n",
      "- jan 2025 - jan 2025\n",
      "- current update : linkedin post\n",
      "- backend : d-jango, llm\n",
      "\n",
      "ðŸ“‚ Projects:\n",
      "\n",
      "ðŸ”¹ Untitled Project\n",
      "   ðŸ› ï¸ Tech Stack: C, Machine Learning, Bootstrap, Excel, SQL, Tailwind CSS, Scikit-Learn, Git, HTML, Pandas, Django, Python, NumPy, Flask, Hugging Face, React.js, Seaborn, Node.js, Matplotlib, JavaScript, GitHub, Java, Transformers, LLMs, CSS, Power BI\n",
      "   ðŸŒ Live Link: https://pranav-interiors-and-decorators.onrender.com/\n",
      "\n",
      "ðŸ”¹ Database: PostgreSQL\n",
      "   ðŸ› ï¸ Tech Stack: PostgreSQL, SQL\n",
      "\n",
      "ðŸ”¹ Current Update : LinkedIN Post\n",
      "   ðŸ› ï¸ Tech Stack: C, CSS, HTML\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "SKILLS_DB = [\n",
    "    'C', 'C++', 'Java', 'Python', 'JavaScript', 'HTML', 'CSS', 'SQL', 'Tailwind CSS',\n",
    "    'Bootstrap', 'React.js', 'Flask', 'Django', 'Node.js', 'Pandas', 'NumPy',\n",
    "    'Matplotlib', 'Seaborn', 'Scikit-Learn', 'Machine Learning', 'LLMs',\n",
    "    'Hugging Face', 'Transformers', 'Power BI', 'PostgreSQL', 'Git', 'GitHub', 'Excel'\n",
    "]\n",
    "\n",
    "def extract_email(text):\n",
    "    match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "def extract_phone(text):\n",
    "    match = re.search(r'\\+91[-\\s]?[0-9]{10}|\\b[7-9]\\d{9}\\b', text)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "def extract_name(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if \"SUMMARY\" in line.upper():\n",
    "            return lines[lines.index(line) - 1].strip()\n",
    "    return lines[0].strip()  # fallback\n",
    "\n",
    "def extract_skills(text):\n",
    "    text = text.lower()\n",
    "    found_skills = []\n",
    "    for skill in SKILLS_DB:\n",
    "        if skill.lower() in text:\n",
    "            found_skills.append(skill)\n",
    "    return list(set(found_skills))\n",
    "\n",
    "def extract_education(text):\n",
    "    lines = text.lower().splitlines()\n",
    "    edu_lines = [line.strip() for line in lines if 'university' in line or 'college' in line or 'cgpa' in line]\n",
    "    return edu_lines\n",
    "\n",
    "def extract_experience_and_projects(text):\n",
    "    lines = text.lower().splitlines()\n",
    "    exp_lines = []\n",
    "    for line in lines:\n",
    "        if any(keyword in line for keyword in ['summary', 'projects', 'jun', 'jan', 'link']):\n",
    "            exp_lines.append(line.strip())\n",
    "    return exp_lines\n",
    "\n",
    "def extract_projects(text):\n",
    "    lines = text.splitlines()\n",
    "    projects = []\n",
    "    current_project = {}\n",
    "\n",
    "    for line in lines:\n",
    "        lower_line = line.lower()\n",
    "\n",
    "        # New project start\n",
    "        if \"post\" in line.lower():\n",
    "            if current_project:\n",
    "                projects.append(current_project)\n",
    "                current_project = {}\n",
    "            current_project['title'] = line.strip()\n",
    "\n",
    "        # Tech stack detection from SKILLS_DB\n",
    "        for skill in SKILLS_DB:\n",
    "            if skill.lower() in lower_line:\n",
    "                current_project.setdefault('tech', set()).add(skill)\n",
    "\n",
    "        # Link extraction\n",
    "        if \"live link\" in lower_line:\n",
    "            current_project['live link'] = line.strip().split(\":\", 1)[-1].strip()\n",
    "\n",
    "    if current_project:\n",
    "        # Final append after last project\n",
    "        if 'tech' in current_project:\n",
    "            current_project['tech'] = list(current_project['tech'])\n",
    "        projects.append(current_project)\n",
    "\n",
    "    # Convert sets to lists\n",
    "    for project in projects:\n",
    "        if 'tech' in project:\n",
    "            project['tech'] = list(project['tech'])\n",
    "\n",
    "    return projects\n",
    "\n",
    "\n",
    "\n",
    "# Extract info\n",
    "email = extract_email(text)\n",
    "phone = extract_phone(text)\n",
    "name = extract_name(text)\n",
    "skills = extract_skills(text)\n",
    "education = extract_education(text)\n",
    "experience = extract_experience_and_projects(text)\n",
    "projects = extract_projects(text)\n",
    "\n",
    "# Display the results\n",
    "print(\"ðŸ“› Name:\", name)\n",
    "print(\"ðŸ“§ Email:\", email)\n",
    "print(\"ðŸ“ž Phone:\", phone)\n",
    "print(\"ðŸ§  Skills Matched:\", len(skills))\n",
    "print(\"ðŸ§© Skills:\", skills)\n",
    "print(\"\\nðŸŽ“ Education:\")\n",
    "for edu in education:\n",
    "    print(\"-\", edu)\n",
    "\n",
    "print(\"\\nðŸ’¼ Experience & Project Highlights:\")\n",
    "for exp in experience:\n",
    "    print(\"-\", exp)\n",
    "\n",
    "print(\"\\nðŸ“‚ Projects:\")\n",
    "for project in projects:\n",
    "    title = project.get(\"title\", \"Untitled Project\")\n",
    "    print(f\"\\nðŸ”¹ {title}\")\n",
    "    \n",
    "    tech = project.get(\"tech\")\n",
    "    if tech:\n",
    "        print(f\"   ðŸ› ï¸ Tech Stack: {', '.join(tech)}\")\n",
    "    \n",
    "    live_link = project.get(\"live link\") or project.get(\"live_link\")\n",
    "    if live_link:\n",
    "        print(f\"   ðŸŒ Live Link: {live_link}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4e04914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Obtaining dependency information for pdfplumber from https://files.pythonhosted.org/packages/e6/c4/d2e09fbc937d1f76baae34e526662cc718e23a904321bf4a40282d190033/pdfplumber-0.11.6-py3-none-any.whl.metadata\n",
      "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.8 kB ? eta -:--:--\n",
      "     --------------------------- ---------- 30.7/42.8 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.8/42.8 kB 524.4 kB/s eta 0:00:00\n",
      "Collecting python-docx\n",
      "  Obtaining dependency information for python-docx from https://files.pythonhosted.org/packages/3e/3d/330d9efbdb816d3f60bf2ad92f05e1708e4a1b9abe80461ac3444c83f749/python_docx-1.1.2-py3-none-any.whl.metadata\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pdfminer.six==20250327 (from pdfplumber)\n",
      "  Obtaining dependency information for pdfminer.six==20250327 from https://files.pythonhosted.org/packages/29/2f/409e174b5a0195aa6a814c7359a1285f1c887a4c84aff17ed03f607c06ba/pdfminer_six-20250327-py3-none-any.whl.metadata\n",
      "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pdfplumber) (11.0.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Obtaining dependency information for pypdfium2>=4.18.0 from https://files.pythonhosted.org/packages/a4/f3/8d3a350efb4286b5ebdabcf6736f51d8e3b10dbe68804c6930b00f5cf329/pypdfium2-4.30.1-py3-none-win_amd64.whl.metadata\n",
      "  Downloading pypdfium2-4.30.1-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/48.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.2/48.2 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (41.0.3)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-docx) (4.9.3)\n",
      "Collecting typing-extensions>=4.9.0 (from python-docx)\n",
      "  Obtaining dependency information for typing-extensions>=4.9.0 from https://files.pythonhosted.org/packages/df/c5/e7a0b0f5ed69f94c8ab7379c599e6036886bffcde609969a5325f47f1332/typing_extensions-4.13.1-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.21)\n",
      "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.2/60.2 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/5.6 MB 4.1 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.2/5.6 MB 3.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.3/5.6 MB 2.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.5/5.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.7/5.6 MB 3.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.0/5.6 MB 3.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.3/5.6 MB 4.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.4/5.6 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.7/5.6 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.8/5.6 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.9/5.6 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.1/5.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.4/5.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.7/5.6 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.9/5.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.6 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.6/5.6 MB 4.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.9/5.6 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.2/5.6 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.3/5.6 MB 4.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.9/5.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.2/5.6 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.4/5.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.6/5.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "   ---------------------------------------- 0.0/244.3 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 225.3/244.3 kB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 244.3/244.3 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading pypdfium2-4.30.1-py3-none-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/3.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.4/3.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.6/3.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.8/3.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.0/3.0 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.2/3.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.4/3.0 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.6/3.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.7/3.0 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.9/3.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.1/3.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.3/3.0 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.5/3.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.7/3.0 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.8/3.0 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.0/3.0 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.7/45.7 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: typing-extensions, pypdfium2, python-docx, pdfminer.six, pdfplumber\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "Successfully installed pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1 python-docx-1.1.2 typing-extensions-4.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ae6e404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"Github | +91-7738544966 | nikhilsutar621@gmail.com | LinkedIn\",\n",
      "    \"email\": \"nikhilsutar621@gmail.com\",\n",
      "    \"phone\": \"+91-7738544966\",\n",
      "    \"skills\": [\n",
      "        \"C\",\n",
      "        \"Machine Learning\",\n",
      "        \"Bootstrap\",\n",
      "        \"Excel\",\n",
      "        \"SQL\",\n",
      "        \"Tailwind CSS\",\n",
      "        \"Scikit-Learn\",\n",
      "        \"Git\",\n",
      "        \"HTML\",\n",
      "        \"Pandas\",\n",
      "        \"Django\",\n",
      "        \"Python\",\n",
      "        \"NumPy\",\n",
      "        \"Flask\",\n",
      "        \"Hugging Face\",\n",
      "        \"React.js\",\n",
      "        \"Seaborn\",\n",
      "        \"Node.js\",\n",
      "        \"Matplotlib\",\n",
      "        \"JavaScript\",\n",
      "        \"PostgreSQL\",\n",
      "        \"GitHub\",\n",
      "        \"Java\",\n",
      "        \"Transformers\",\n",
      "        \"LLMs\",\n",
      "        \"CSS\",\n",
      "        \"Power BI\"\n",
      "    ],\n",
      "    \"education\": [\n",
      "        \"konkan gyanpeeth college of engineering , affiliated to the university of mumbai\",\n",
      "        \"artificial intelligence and data science | cgpa of 5 sems: 6.70 2023 - 2026 (expected)\"\n",
      "    ],\n",
      "    \"experience\": [\n",
      "        \"github | +91-7738544966 | nikhilsutar621@gmail.com | linkedin\",\n",
      "        \"summary\",\n",
      "        \"as flask, django, and bootstrap, with ongoing learning in react.js. experienced in version control with git and\",\n",
      "        \"github and adept at deploying projects on vercel. committed to leveraging ai tools, including chatgpt, to\",\n",
      "        \"backend : node.js , flask , django\",\n",
      "        \"projects\",\n",
      "        \"current update : linkedin post\",\n",
      "        \"backend : d-jango, llm\",\n",
      "        \"2. success classes of engineering jun 2024 - jun 2024\",\n",
      "        \"live link : https://success-classes-of-engineering.vercel.app/\",\n",
      "        \"live link : https://pranav-interiors-and-decorators.onrender.com/ jan 2025 - jan 2025\",\n",
      "        \"backend: django, python\",\n",
      "        \"live link : https://carpentrycoder.github.io/resume/ jan 2025 - jan 2025\"\n",
      "    ],\n",
      "    \"projects\": [\n",
      "        {\n",
      "            \"tech\": [\n",
      "                \"C\",\n",
      "                \"Machine Learning\",\n",
      "                \"Bootstrap\",\n",
      "                \"SQL\",\n",
      "                \"Scikit-Learn\",\n",
      "                \"Git\",\n",
      "                \"Pandas\",\n",
      "                \"Django\",\n",
      "                \"Python\",\n",
      "                \"NumPy\",\n",
      "                \"Flask\",\n",
      "                \"Hugging Face\",\n",
      "                \"React.js\",\n",
      "                \"Seaborn\",\n",
      "                \"Node.js\",\n",
      "                \"Matplotlib\",\n",
      "                \"JavaScript\",\n",
      "                \"GitHub\",\n",
      "                \"Java\",\n",
      "                \"Transformers\",\n",
      "                \"LLMs\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Current Update : LinkedIN Post\",\n",
      "            \"tech\": [\n",
      "                \"C\",\n",
      "                \"HTML\",\n",
      "                \"CSS\",\n",
      "                \"Django\",\n",
      "                \"Python\",\n",
      "                \"Flask\"\n",
      "            ],\n",
      "            \"live link\": \"https://pranav-interiors-and-decorators.onrender.com/ Jan 2025 - Jan 2025\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Database: PostgreSQL\",\n",
      "            \"tech\": [\n",
      "                \"C\",\n",
      "                \"SQL\",\n",
      "                \"Tailwind CSS\",\n",
      "                \"Git\",\n",
      "                \"HTML\",\n",
      "                \"PostgreSQL\",\n",
      "                \"CSS\",\n",
      "                \"GitHub\",\n",
      "                \"Excel\",\n",
      "                \"Power BI\"\n",
      "            ],\n",
      "            \"live link\": \"https://carpentrycoder.github.io/Resume/ Jan 2025 - Jan 2025\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import pdfplumber\n",
    "import docx\n",
    "\n",
    "# SKILLS_DB and your extract_ functions defined here...\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        return \"\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
    "\n",
    "def read_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    return \"\\n\".join(para.text for para in doc.paragraphs)\n",
    "\n",
    "def read_txt(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def extract_resume_data(file_path):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        text = read_pdf(file_path)\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        text = read_docx(file_path)\n",
    "    elif file_path.endswith(\".txt\"):\n",
    "        text = read_txt(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "    # Extract info\n",
    "    email = extract_email(text)\n",
    "    phone = extract_phone(text)\n",
    "    name = extract_name(text)\n",
    "    skills = extract_skills(text)\n",
    "    education = extract_education(text)\n",
    "    experience = extract_experience_and_projects(text)\n",
    "    projects = extract_projects(text)\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"email\": email,\n",
    "        \"phone\": phone,\n",
    "        \"skills\": skills,\n",
    "        \"education\": education,\n",
    "        \"experience\": experience,\n",
    "        \"projects\": projects\n",
    "    }\n",
    "\n",
    "# Usage\n",
    "resume_info = extract_resume_data(\"TE_Resume.pdf\")\n",
    "print(json.dumps(resume_info, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7487cda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CSV file 'parsed_resumes.csv' created successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Sample data (you can append more dictionaries like this to the list)\n",
    "resume_data = [\n",
    "    {\n",
    "        \"Name\": \"NIKHIL M. SUTAR\",\n",
    "        \"Email\": \"nikhilsutar621@gmail.com\",\n",
    "        \"Phone\": \"+91-7738544966\",\n",
    "        \"Education\": \"konkan gyanpeeth college of engineering , affiliated to the university of mumbai; artificial intelligence and data science | cgpa of 5 sems: 6.70\",\n",
    "        \"Skills\": ['Python', 'Java', 'C', 'JavaScript', 'Django', 'Flask', 'React', 'Machine Learning', 'LLM', 'SQL',\n",
    "                   'Pandas', 'Numpy', 'Seaborn', 'Bootstrap', 'GitHub', 'Tailwind', 'HTML', 'CSS', 'Tailwind CSS',\n",
    "                   'React.js', 'Node.js', 'NumPy', 'Matplotlib', 'Scikit-Learn', 'LLMs', 'Hugging Face',\n",
    "                   'Transformers', 'Power BI', 'Excel', 'Git', 'PostgreSQL']\n",
    "    },\n",
    "    # Add more entries here...\n",
    "]\n",
    "\n",
    "# CSV file name\n",
    "filename = \"parsed_resumes.csv\"\n",
    "\n",
    "# Write to CSV\n",
    "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Name\", \"Email\", \"Phone\", \"Education\", \"Skills\"])\n",
    "    writer.writeheader()\n",
    "    for entry in resume_data:\n",
    "        entry['Skills'] = ', '.join(entry['Skills'])  # convert list to string\n",
    "        writer.writerow(entry)\n",
    "\n",
    "print(f\"âœ… CSV file '{filename}' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59f53c8-b386-40a7-8db4-95ac27cb77b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tzdata in c:\\users\\admin\\anaconda3\\lib\\site-packages (from faker) (2023.3)\n",
      "Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.9 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.8/1.9 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: faker\n",
      "Successfully installed faker-37.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66a271c-016b-4724-a05c-75ef73d5b4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CSV file 'parsed_fake_resumes.csv' with 20 fake resumes created successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Define skill pool\n",
    "skill_pool = [\n",
    "    'Python', 'Java', 'C', 'C++', 'JavaScript', 'TypeScript', 'HTML', 'CSS',\n",
    "    'SQL', 'Bootstrap', 'Tailwind CSS', 'React.js', 'Vue.js', 'Angular',\n",
    "    'Flask', 'Django', 'Node.js', 'Express.js',\n",
    "    'Pandas', 'NumPy', 'Matplotlib', 'Seaborn', 'Plotly',\n",
    "    'Scikit-Learn', 'Machine Learning', 'Deep Learning', 'LLMs',\n",
    "    'Hugging Face', 'Transformers', 'TensorFlow', 'PyTorch',\n",
    "    'OpenCV', 'Power BI', 'Excel', 'Git', 'GitHub', 'Docker', 'PostgreSQL', 'MongoDB'\n",
    "]\n",
    "\n",
    "# College and course sample data\n",
    "colleges = [\n",
    "    \"IIT Bombay\", \"VJTI Mumbai\", \"COEP Pune\", \"BITS Pilani\", \"MIT Manipal\", \n",
    "    \"Konkan Gyanpeeth College of Engineering\", \"Thakur College\", \"Sardar Patel Institute\"\n",
    "]\n",
    "courses = [\n",
    "    \"Artificial Intelligence and Data Science\", \"Computer Engineering\",\n",
    "    \"Information Technology\", \"Electronics and Telecommunication\", \"Data Science\"\n",
    "]\n",
    "\n",
    "# Generate multiple fake resume entries\n",
    "def generate_fake_resumes(n=10):\n",
    "    resumes = []\n",
    "    for _ in range(n):\n",
    "        name = fake.name()\n",
    "        email = fake.email()\n",
    "        phone = fake.phone_number()\n",
    "        college = random.choice(colleges)\n",
    "        course = random.choice(courses)\n",
    "        cgpa = round(random.uniform(6.0, 9.5), 2)\n",
    "\n",
    "        education = f\"{college}; {course} | CGPA: {cgpa}\"\n",
    "\n",
    "        skills = random.sample(skill_pool, k=random.randint(8, 15))  # Random 8-15 skills\n",
    "\n",
    "        resumes.append({\n",
    "            \"Name\": name,\n",
    "            \"Email\": email,\n",
    "            \"Phone\": phone,\n",
    "            \"Education\": education,\n",
    "            \"Skills\": skills\n",
    "        })\n",
    "    return resumes\n",
    "\n",
    "# CSV file name\n",
    "filename = \"parsed_fake_resumes.csv\"\n",
    "\n",
    "# Generate data\n",
    "resume_data = generate_fake_resumes(20)  # change number for more/less candidates\n",
    "\n",
    "# Write to CSV\n",
    "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Name\", \"Email\", \"Phone\", \"Education\", \"Skills\"])\n",
    "    writer.writeheader()\n",
    "    for entry in resume_data:\n",
    "        entry['Skills'] = ', '.join(entry['Skills'])  # convert list to string\n",
    "        writer.writerow(entry)\n",
    "\n",
    "print(f\"âœ… CSV file '{filename}' with {len(resume_data)} fake resumes created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057c230-acff-4065-bbc3-a3d96bcd53d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
